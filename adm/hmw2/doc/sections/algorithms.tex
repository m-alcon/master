\section{Algorithms}
\subsection{EM}
Expectation-maximization algorithm (EM) \cite{em,wiki_em,rapid_em} is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.

The basic approach and logic of this clustering method is as follows. Suppose you measure a single continuous variable in a large sample of observations. Further, suppose that the sample consists of two clusters of observations with different means (and perhaps different standard deviations); within each sample, the distribution of values for the continuous variable follows the normal distribution. The goal of EM clustering is to estimate the means and standard deviations for each cluster so as to maximize the likelihood of the observed data (distribution). Put another way, the EM algorithm attempts to approximate the observed distributions of values based on mixtures of different distributions in different clusters. The results of EM clustering are different from those computed by k-means clustering. The latter will assign observations to clusters to maximize the distances between clusters. The EM algorithm does not compute actual assignments of observations to clusters, but classification probabilities. In other words, each observation belongs to each cluster with a certain probability. Of course, as a final result you can usually review an actual assignment of observations to clusters, based on the (largest) classification probability.

\subsection{DBSCAN}
Density-based spatial clustering of applications with noise (DBSCAN) \cite{dbscan,wiki_dbscan} is a data clustering algorithm. Specifically, it is a density-based clustering non-parametric algorithm. So, given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away).


This algorithm require two parameters:
\begin{itemize}
    \item $\varepsilon$: the maximum distance between two points for them to be considered as in the same neighborhood.
    \item $minPts$: the minimum number of points required to form a dense region.
\end{itemize}

Given $\varepsilon$ and $minPts$, the DBSCAN algorithm can be abstracted into the following steps:
\begin{enumerate}
    \item Find the points in the $\varepsilon$ neighborhood of every point, and identify the core points with more than $minPts$ neighbors.
    \item Find the connected components of core points on the neighbor graph, ignoring all non-core points.
    \item Assign each non-core point to a nearby cluster if the cluster is an  $\varepsilon$ neighbor, otherwise assign it to noise.
\end{enumerate}